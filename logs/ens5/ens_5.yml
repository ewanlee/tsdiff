model:
  type: diffusion # dsm and diffusion
  network: dualenc_general
  t0: 0
  t1: 5000
  dual_encoding: False

  global_edge_cutoff: 10.0
  global_edge_order: 4
  global_pred_edge_order: 3
  global_encoder:
    name: schnet
    edge_emb: False
    num_convs: 7
    cutoff: 10.0
    smooth_conv: False
    mlp_act: swish
    hidden_dim: 256
  
  local_edge_cutoff: 0.001
  local_edge_order: 1
  local_pred_edge_order: 1
  local_encoder:
    name: dimenetpp
    num_convs: 6
    num_output_layers: 3
    num_before_skip: 1
    num_after_skip: 2
    hidden_dim: 256
    cutoff: 10.0
    num_spherical: 7
    num_radial: 7

  TS: True
  # condensed edge generation
  
  # atom/edge embedding
  feat_dim: 25
  hidden_dim: 256
  edge_encoder: mlp
    
  # grad dist mlp/condensed edge_cat
  mlp_act: swish
  edge_cat_act: swish

  # diffusion process
  beta_schedule: sigmoid
  beta_start: 1.e-7
  beta_end: 2.e-3
  num_diffusion_timesteps: 5000

train:
  seed: 12
  # total training data : 26148
  batch_size: 200
  val_freq: 1000
  log_freq: 1000
  max_iters: 400000 #5000 * 100
  max_grad_norm: 3000.0  # Different from QM9
  anneal_power: 2.0
  optimizer:
    type: adam
    lr: 5.e-4
    weight_decay: 0.
    beta1: 0.95
    beta2: 0.999
  scheduler:
    type: plateau
    factor: 0.8
    patience: 10
    min_lr: 0.000125

dataset:
  train: data/TS/wb97xd3/random_split_42/train_data.pkl
  val: data/TS/wb97xd3/random_split_42/val_data.pkl
  test: data/TS/wb97xd3/random_split_42/test_data.pkl
